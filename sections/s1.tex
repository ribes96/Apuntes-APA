\section{}
\subsection{Introducción a ML}
\paragraph{Ejemplo 1}
Se pretende medir la temperatura ($t$) en un punto de una central nuclear, pero la temperatura es tan alta que no se puede medir directamente con ningún sensor. Se intentará deducir la temperatura así:
\begin{itemize}
\item $t$ - temperatura a predecir (variable)
\item $x$ - vector de variables medibles que posiblemente inciden en $t$
\item $z$ - vector de variables \textbf{NO medibles} que posiblemente inciden en $t$
\end{itemize}

La relación completa es $ t = \delta(x,z)$, que es una función.

Pero no conocemos $z$ \MVRightarrow Aun conociendo $x$, el valor de $t$ oscila. La relación entre $t$ y $x$ se hace \textit{estocástica}

$p(x,t)$ será la probabilidad de que con esa $x$ se tenga esa temperatura.

Hay que construir una función $t = y(x)$ donde $t$ sea el valor más plausible. El problema es que no conocemos $p$

La forma de atacar el problema será recolectar datos $\{(x_1, t_1),(x_2, t_2), \dots ,(x_n, t_n)\} = D$

$(x_n,t_n) \sim^{i.i.p.} p$ (variables independientes e identicamente distribuidas)


El objetivo del \textit{Machine Learning} (ML) es obtener $y$ a partir de $D$. En este caso es un problema de \textit{regresión}



\paragraph{Ejemplo 2}
Se tiene una planta de reciclaje, y se quieren clasificar los objetos que van pasando por la cinta. Los datos son:
\begin{itemize}
\item $t$ - tipo de producto
\item $x$ - los atributos de los productos que captamos con una cámara
\item $z$ - los atributos que no captamos con la cámara
\end{itemize}

Es el mismo problema de antes, pero ahora $t$ es discreta. Se trata entonces de un problema de \textit{clasificación}.

\subsection{Ejemplo introductorio: el ajuste polinómico}

Tenemos $x \in \mathbb{R}$ y queremos predecir $t \in \mathbb{R}$ (\textit{Regresión})

En todos los problemas nos encontraremos con:
\begin{itemize}
\item $x_n \in (0,1)$, $x_n \sim U(0,1) $, (un conjunto de observaciones)
\item $t_n = sin(2\pi x_n) + \varepsilon, \varepsilon \in N(0,\sigma^2)$, normalmente $\sigma^2 = 0.3^2$, y donde $\varepsilon$ es el ruido aparentemente aleatorio, que proviene de los datos que no conocemos o de errores en la medición.
\end{itemize}

Vamos a intentar ajustar los datos. Sabemos que si los datos son continuos (no dan saltos) podemos ajustarlos con un polinomio en un intervalo:
\begin{itemize}
\item $P_n := \{c_0 + c_1x + c_2x^2 + \dots + c_nx^n\} = \{\sum_{i = 0}^n c_ix^i | c_i \in \mathbb{R} \}$
\item $C \in \mathbb{R}^{n + 1}$ son todos los parámetros.
\item Llamamos $y(x;c) = \sum_{i = 0}^{M} c_ix^i$ un modelo
\item Respecto a $X$, $y$ es una función no lineal
\item Respecto a $C$, $y$ es una función lineal
\end{itemize}

Diremos que un modelo es lineal cuando lo es respecto a los parámetros.

Ajustamos $y$ a los datos $\{(x_1,t_1),(x_2,t_2), \dots (x_n, t_n)\}$ definiendo una función de error (la función de error cuadrático):

\begin{equation*}
E(c) = \frac{1}{2} \sum_{n = 1}^{N} (y(x_n;C) - t_n)^2
\end{equation*}

Como $E$ depende automáticamente de $C$, derivamos e igualamos a 0 para encontrar el mínimo. Hay que hacer $n$ derivadas, una para cada $c_j$:
\begin{equation*}
\frac{\partial E}{\partial c_j} = \frac{1}{2} \sum_{n = 1}^{N} 2(y(x_n;C) - t_n)(x_n)^j
\end{equation*}

\begin{equation*}
\frac{\partial E}{\partial c_j} = \sum_{n = 0}^{N} \Big(\sum_{i = 0}^{M} (c_ix_n^i - t_n) \Big) x_n^j = 0
\end{equation*}

El problema de todo esto es que no sabemos qué grado de polinomio deberíamos usar para reflejar el comportamiento de la variable.
\begin{itemize}
\item Si es demasiado pequeño no seremos capaces de ajustar la parte regular $(y)$ de los datos (infra-ajuste)
\item Si es demasiado grande se ajustará la parte regular $(y)$ y también el ruido (sobre-ajuste)
\end{itemize}

\subsubsection*{Cómo elegir el grado del polinomio?}
Únicamente conociendo $E(C)$ no se puede saber. Para hacerlo se usa una muestra alternativa de datos de validación. Esta muestra debería tener más datos.

Si observamos el error producido en nuestros datos con diferentes grados de polinomios, obviamente será más pequeño cuanto más grande sea el polinomio, puesto que tiene más flexibilidad. Pero si miramos qué ocurre con los datos de validación, veremos que al principio el error desciende, pero llega un punto en que empieza a subir. El punto mínimo se corresponde con el grado correcto.

El error empezará a subir porque el sobre-ajuste se ha adaptado a los datos aleatorios, pero en la muestra de validación no tienen por qué ser los mismos, y produce más error.

Si la muestra de validación tiene pocos datos, el mínimo estará poco definido, será más redondeado y más difícil de localizar.

\subsubsection*{Alternativa}
Pero no siempre es posible tener suficientes datos de validación. Para esto hay una alternativa.

Uno se pregunta: ¿Si un polinomio de grado 9 ``contiene'' a los de grado más pequeño, no podría ocurrir que eligiéramos uno de grado mayor, y que él mismo anulara los coeficientes sobrantes hasta que sea del grado adecuado?

La respuesta es que espontaneamente esto no pasa, puesto que para igualar los datos aleatorios son necesarios coeficientes muy grandes. Si queremos que ocurra tenemos que forzarlo de alguna manera. Para hacerlo, redefiniremos nuestra función de error, de manera que también penalice los coeficientes demasiado grandes. Penalizaremos la norma 2, que equivale a la ``distancia'' pitagórica.

¿Pero cuanto tenemos que penalizarlo? Si nos pasamos o nos quedamos cortos no servirá de nada. Como no sabemos cuanto tenemos que penalizar, usaremos un parámetro $\lambda$ que regulará la penalización que hacemos.

La función de error queda así:
\begin{equation*}
E(C) = \frac{1}{2} \sum_{n = 1}^{N} \Big( y(x_n;C) - t_n\Big)^2 + \frac{\lambda}{2}||c||^2
\end{equation*}

El $\frac{\lambda}{2}$ es simplemente para que al derivar quede más simple. Podría ser solo $\lambda$

\subsection{Conceptos de inferencia estadística}

$D = \{x_1, \dots x_n\}$ es una realización de una variable aleatoria (v.a.) $X_n$ que tiene una función de distribución conocida $p(x_n;\theta), \theta \in \Theta$

Pero esa función de distribución tiene unos parámetros, y nos gustaría saber cuáles usar.

Por ejemplo, si se trata de una distribución normal, sabemos que nuestros datos se corresponden con $N(x, \mu, \sigma^2)$, pero viendo los datos no sabemos qué valores de $\mu$ y $\sigma^2$ deberíamos cojer para que se adaptaran lo más posible a los datos que tenemos.

Vamos a cojer los datos que maximicen nuestra verosimilitud (likelihood), esto es, los que hagan que sea más probable recoger los datos $D$

El objetivo es obtener una estimación $\hat{\theta}$ de $\theta$, dado $D$

La probabilidad de recoger una muestra $x_i$ es $p(x_i,\theta)$

Puesto que sabemos que los datos son i.i.d, la probabilidad de cojer todos los datos $D$ es el producto de cada uno de ellos.

La probabilidad de obtener $D$ es:
\begin{equation*}
P_n(D,\theta) = \prod_{n = 1}^{N} p(x_n,\theta)
\end{equation*}

Definimos la función de verosimilitud (likelihood) así:
\begin{equation*}
\mathcal{L} : \theta \rightarrow \mathbb{R}
\end{equation*}

\begin{equation*}
\theta \rightarrow \mathcal{L}(\theta) = P_n(D;\theta)
\end{equation*}

Es decir, es una función que indica cómo de probable es haber recogido los datos $D$ usando los parámetros $\theta$.

Elegiremos los paráetros $\theta$ que maximicen esa probabilidad, los que maximicen $P(D,\theta) = \prod_{n = 1}^{N} p(x_n,\theta)$

El estimador de máxima verosimilitud es $\hat{\theta} = \text{argmax}\  \mathcal{L}(\theta)$, $\theta \in \Theta$

Si es de una sola variable, la forma de hacerlo es derivar e igualar a 0.

Es conveniente operar con el logaritmo de $\alpha$, pues simplifica la maximización de un producto:
\begin{equation*}
\ln{(p_1p_2\dots p_n)} = \ln{(p_1)} + \ln{(p_2)} + \dots + \ln{(p_n)}
\end{equation*}

\subsubsection*{Ejemplo}
Tenemos un conjunto de datos $D = \{x_1,x_2,\dots, x_n\}$ que siguen una distribución normal $X_n \sim N(x_n,\mu, \sigma^2)$

Se sabe que la función de densidad de la distrubión normal es:

\begin{equation*}
  N(x, \mu, \sigma^2) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x - \mu)^2}{2\sigma^2}}
\end{equation*}

Entonces la probabilidad de haber cogido los datos $D$ es:

\begin{equation*}
  P(D, \mu, \sigma^2) = \prod_{i = 1}^{n} \Big( \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x_i - \mu)^2}{2\sigma^2}} \Big)
\end{equation*}

Pero para hacer los cálculos más sencillos trabajaremos con el logaritmo, que no cambia los máximos relativos. Además, le vamos a cambiar el signo, y ya no buscaremos maximizarlo, sino minimizarlo.

\begin{equation*}
  l = -\ln(P(D, \mu, \sigma^2)) = -\ln \prod_{i = 1}^{n} \Big( \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x_i - \mu)^2}{2\sigma^2}} \Big) = -\sum_{i = 1}^{N} \ln \big( \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x_i - \mu)^2}{2\sigma^2}} \big)
\end{equation*}

Se simplifica así:

\begin{equation*}
  l = -\sum_{i = 1}^{N} \ln \big( \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x_i - \mu)^2}{2\sigma^2}} \big)
\end{equation*}

\begin{equation*}
  l = -\sum_{i = 1}^{N} \Big[ \ln \big( \frac{1}{\sigma\sqrt{2\pi}} \big) + \ln \big( e^{-\frac{(x_i - \mu)^2}{2\sigma^2}} \big) \Big]
\end{equation*}

\begin{equation*}
  l = -\sum_{i = 1}^{N} \Big[ -\ln \big( \sigma\sqrt{2\pi} \big) - \frac{(x_i - \mu)^2}{2\sigma^2} \Big]
\end{equation*}

\begin{equation*}
  l = \sum_{i = 1}^{N} \Big[ \ln \big( \sigma\sqrt{2\pi} \big) + \frac{(x_i - \mu)^2}{2\sigma^2} \Big]
\end{equation*}

Ahora derivamos respecto de $\mu$ y de $\sigma^2$ e igualamos a 0 para encontrar los extremos:

\begin{equation*}
\frac{\partial l}{\partial \mu} = \sum_{i = 1}^{N} \Big[ 0 + \frac{1}{2\sigma^2} \cdot 2(x_i - \mu)(-1) \Big]
\end{equation*}

\begin{equation*}
\frac{\partial l}{\partial \mu} = \sum_{i = 1}^{N} \Big[ -\frac{x_i - \mu}{\sigma^2} \Big]
\end{equation*}

\begin{equation*}
\frac{\partial l}{\partial \mu} = -\frac{1}{\sigma^2}\sum_{i = 1}^{N} \Big[ x_i - \mu \Big] = 0
\end{equation*}

\begin{equation*}
\sum_{i = 1}^{N} x_i - \sum_{i = 1}^{N} \mu = 0
\end{equation*}

\begin{equation*}
\sum_{i = 1}^{N} x_i - N\mu = 0
\end{equation*}

\begin{equation*}
\sum_{i = 1}^{N} x_i = N\mu
\end{equation*}

\begin{equation*}
\mu = \frac{1}{N}\sum_{i = 1}^{N} x_i
\end{equation*}

Y respecto de $\sigma^2$:

\begin{equation*}
  l = \sum_{i = 1}^{N} \Big[ \ln \big( \sigma\sqrt{2\pi} \big) + \frac{(x_i - \mu)^2}{2\sigma^2} \Big]
\end{equation*}

\begin{equation*}
  \frac{\partial l}{\partial \sigma^2} = \sum_{i = 1}^{N} \Big[ \frac{1}{\sigma\sqrt{2\pi}} \cdot \frac{\sqrt{2\pi}}{2\sigma} + \frac{(x_i - \mu)^2}{2} \big( -\frac{1}{\sigma^4} \big) \Big]
\end{equation*}

\begin{equation*}
  \frac{\partial l}{\partial \sigma^2} = \sum_{i = 1}^{N} \Big[ \frac{1}{2\sigma^2} - \frac{(x_i - \mu)^2}{2\sigma^4} \Big] = 0
\end{equation*}

\begin{equation*}
\sum_{i = 1}^{N} \Big[ \frac{1}{2\sigma^2} \Big] - \sum_{i = 1}^{N} \Big[\frac{(x_i - \mu)^2}{2\sigma^4} \Big] = 0
\end{equation*}

\begin{equation*}
\frac{N}{2\sigma^2} = \frac{1}{2\sigma^4}\sum_{i = 1}^{N} (x_i - \mu)^2
\end{equation*}

\begin{equation*}
\sigma^2 = \frac{1}{N}\sum_{i = 1}^{N} (x_i - \mu)^2
\end{equation*}

De este modo hemos encontrado las ecuaciones clásicas para encontrar la media y la varianza muestral, que son la media y varianza más probables teniendo en cuenta los datos que hemos recogido.

Se podría aplicar el mismo procedimiento con alguna otra distribución.

\hspace{1cm}

\textit{Nota: habría que asegurarse que realmente se trata de mínimos mirando la segunda derivada y comprobando que da valores positivos. Se deja como ejercicio}

%1.4
\subsection{Propiedades de un estimador}
